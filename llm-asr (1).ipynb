{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9812,"sourceType":"datasetVersion","datasetId":5793},{"sourceId":6871056,"sourceType":"datasetVersion","datasetId":3948432},{"sourceId":7749642,"sourceType":"datasetVersion","datasetId":4530673}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Usage\nimport torch\nfrom transformers import LlamaTokenizer, LlamaForCausalLM\n\ntokenizer = LlamaTokenizer.from_pretrained('sarvamai/OpenHathi-7B-Hi-v0.1-Base')\nmodel = LlamaForCausalLM.from_pretrained('sarvamai/OpenHathi-7B-Hi-v0.1-Base', torch_dtype=torch.bfloat16)\n\nprompt = \"मैं एक अच्छा हाथी हूँ\"\ninputs = tokenizer(prompt, return_tensors=\"pt\")\n\n# Generate\ngenerate_ids = model.generate(inputs.input_ids, max_length=30)\ntokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-06T12:19:55.381120Z","iopub.execute_input":"2024-03-06T12:19:55.381427Z","iopub.status.idle":"2024-03-06T12:21:37.210641Z","shell.execute_reply.started":"2024-03-06T12:19:55.381402Z","shell.execute_reply":"2024-03-06T12:21:37.209141Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/936 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f35dbbd210664769a5f4b7fbd40b561b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/968k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a26766bd983f43d1b6753dfae431ffe3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10301d6075f74a4b91f5a5e6dbe73fba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fc0a9052c6a4d49a32f202fb91a1987"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/667 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"283bf60a7723498fb8590757532155f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"badc1ddae2114ddfbdb339b596f8eed8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a2f4ecdd9c5400aae1bd469f4961a76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2ee8c3696754a8583d411680b6dc33e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b758768966b54c869fbe16957c1ce176"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4da16b683a584a1991cf2474b9f9323c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"156d4844629d4c49b30b7315c985b341"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d549cbf77d84390916e592de7a8ab24"}},"metadata":{}},{"name":"stderr","text":"Keyword arguments {'add_special_tokens': False} not recognized.\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"\"मैं एक अच्छा हाथी हूँ।\\n\\nI'm a good elephant, I'm a good elephant,\""},"metadata":{}}]},{"cell_type":"code","source":"!pip install SpeechRecognition","metadata":{"execution":{"iopub.status.busy":"2024-03-06T12:21:37.213798Z","iopub.execute_input":"2024-03-06T12:21:37.214206Z","iopub.status.idle":"2024-03-06T12:21:52.499787Z","shell.execute_reply.started":"2024-03-06T12:21:37.214182Z","shell.execute_reply":"2024-03-06T12:21:52.498526Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting SpeechRecognition\n  Downloading SpeechRecognition-3.10.1-py2.py3-none-any.whl.metadata (28 kB)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from SpeechRecognition) (2.31.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from SpeechRecognition) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\nDownloading SpeechRecognition-3.10.1-py2.py3-none-any.whl (32.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: SpeechRecognition\nSuccessfully installed SpeechRecognition-3.10.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import LlamaTokenizer, LlamaForCausalLM\nimport speech_recognition as sr\nfrom pydub import AudioSegment\n\n# Initialize tokenizer and model\ntokenizer = LlamaTokenizer.from_pretrained('sarvamai/OpenHathi-7B-Hi-v0.1-Base')\nmodel = LlamaForCausalLM.from_pretrained('sarvamai/OpenHathi-7B-Hi-v0.1-Base', torch_dtype=torch.bfloat16)\n\n# Initialize the recognizer\nrecognizer = sr.Recognizer()\n\n# Load the MP3 audio file\nmp3_file = \"/kaggle/input/indian-languages-audio-dataset/Indian_Languages_Audio_Dataset/Hindi/10304.mp3\"\nwav_file = \"/kaggle/working/audio.wav\"\n\n# Convert MP3 to WAV\naudio = AudioSegment.from_mp3(mp3_file)\naudio.export(wav_file, format=\"wav\")\n\n# Open the WAV audio file\nwith sr.AudioFile(wav_file) as source:\n    # Record the audio\n    audio_data = recognizer.record(source)\n\n# Convert speech to text\ntry:\n    transcript = recognizer.recognize_google(audio_data, language=\"hi-IN\")  # Specify the language if needed\n    print(\"Transcription: \", transcript)\nexcept sr.UnknownValueError:\n    print(\"Google Speech Recognition could not understand the audio\")\nexcept sr.RequestError as e:\n    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n\n# Now, use the transcribed text as the prompt\nprompt = transcript\ninputs = tokenizer(prompt, return_tensors=\"pt\")\n\n# Generate text based on the transcribed text\ngenerate_ids = model.generate(inputs.input_ids, max_length=30)\ngenerated_text = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n\nprint(\"Generated Text: \", generated_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T12:21:52.501341Z","iopub.execute_input":"2024-03-06T12:21:52.501677Z","iopub.status.idle":"2024-03-06T12:23:08.410747Z","shell.execute_reply.started":"2024-03-06T12:21:52.501647Z","shell.execute_reply":"2024-03-06T12:23:08.409727Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"324355d5e8c4460286789e568d2f8d4b"}},"metadata":{}},{"name":"stderr","text":"Keyword arguments {'add_special_tokens': False} not recognized.\n","output_type":"stream"},{"name":"stdout","text":"Transcription:  नामक एक स्थानीय पेशेवर बास्केटबॉल टीम के अगले प्रदर्शन\nGenerated Text:  नामक एक स्थानीय पेशेवर बास्केटबॉल टीम के अगले प्रदर्शन के लिए एक विज्ञापन के लिए एक मॉडल के रूप में काम किया\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install translate","metadata":{"execution":{"iopub.status.busy":"2024-03-06T12:23:08.413064Z","iopub.execute_input":"2024-03-06T12:23:08.413370Z","iopub.status.idle":"2024-03-06T12:23:22.555443Z","shell.execute_reply.started":"2024-03-06T12:23:08.413344Z","shell.execute_reply":"2024-03-06T12:23:22.554232Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting translate\n  Downloading translate-3.6.1-py2.py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from translate) (8.1.7)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from translate) (5.1.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from translate) (2.31.0)\nCollecting libretranslatepy==2.1.1 (from translate)\n  Downloading libretranslatepy-2.1.1-py3-none-any.whl.metadata (233 bytes)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->translate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->translate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->translate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->translate) (2024.2.2)\nDownloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\nDownloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\nInstalling collected packages: libretranslatepy, translate\nSuccessfully installed libretranslatepy-2.1.1 translate-3.6.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install git+https://github.com/openai/whisper.git -q","metadata":{"execution":{"iopub.status.busy":"2024-03-06T12:23:22.556877Z","iopub.execute_input":"2024-03-06T12:23:22.557193Z","iopub.status.idle":"2024-03-06T12:23:56.554717Z","shell.execute_reply.started":"2024-03-06T12:23:22.557166Z","shell.execute_reply":"2024-03-06T12:23:56.553556Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import whisper\nmodel = whisper.load_model(\"large\")","metadata":{"execution":{"iopub.status.busy":"2024-03-06T12:23:56.556349Z","iopub.execute_input":"2024-03-06T12:23:56.557232Z","iopub.status.idle":"2024-03-06T12:24:52.180787Z","shell.execute_reply.started":"2024-03-06T12:23:56.557191Z","shell.execute_reply":"2024-03-06T12:24:52.179730Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████████████████████████████████| 2.88G/2.88G [00:22<00:00, 136MiB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"audio=whisper.load_audio(\"/kaggle/input/indian-languages-audio-dataset/Indian_Languages_Audio_Dataset/Hindi/10304.mp3\")\naudio = whisper.pad_or_trim(audio) ","metadata":{"execution":{"iopub.status.busy":"2024-03-06T12:28:09.511818Z","iopub.execute_input":"2024-03-06T12:28:09.512750Z","iopub.status.idle":"2024-03-06T12:28:09.610100Z","shell.execute_reply.started":"2024-03-06T12:28:09.512717Z","shell.execute_reply":"2024-03-06T12:28:09.609250Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# make log-Mel spectrogram and move to the same device as the model\nmel = whisper.log_mel_spectrogram(audio, n_mels=128).to(model.device)\n\n# detect the spoken language\n_, probs = model.detect_language(mel)\nprint(f\"Detected language: {max(probs, key=probs.get)}\")\n\n# decode the audio\noptions = whisper.DecodingOptions()\nresult = whisper.decode(model, mel, options)\n\n# print the recognized text\nprint(result.text)\n     ","metadata":{"execution":{"iopub.status.busy":"2024-03-06T12:28:12.728931Z","iopub.execute_input":"2024-03-06T12:28:12.729323Z","iopub.status.idle":"2024-03-06T12:28:17.223012Z","shell.execute_reply.started":"2024-03-06T12:28:12.729283Z","shell.execute_reply":"2024-03-06T12:28:17.221743Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Detected language: hi\nनामक एक इस्थानीय पेशेवर बास्केटबॉल टीम के अगले पर्दसन के लिए\n","output_type":"stream"}]},{"cell_type":"code","source":"results=result.text","metadata":{"execution":{"iopub.status.busy":"2024-03-06T12:28:27.326057Z","iopub.execute_input":"2024-03-06T12:28:27.328739Z","iopub.status.idle":"2024-03-06T12:28:27.334051Z","shell.execute_reply.started":"2024-03-06T12:28:27.328700Z","shell.execute_reply":"2024-03-06T12:28:27.332975Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n# Create a DataFrame\ndf = pd.DataFrame({\n    \"OpenHathi\": generated_text,\n    \"WhisperAI\": results\n},index=[0, 1])\n\ndf","metadata":{"execution":{"iopub.status.busy":"2024-03-06T12:29:22.885379Z","iopub.execute_input":"2024-03-06T12:29:22.886400Z","iopub.status.idle":"2024-03-06T12:29:22.897057Z","shell.execute_reply.started":"2024-03-06T12:29:22.886364Z","shell.execute_reply":"2024-03-06T12:29:22.896087Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                           OpenHathi  \\\n0  नामक एक स्थानीय पेशेवर बास्केटबॉल टीम के अगले ...   \n1  नामक एक स्थानीय पेशेवर बास्केटबॉल टीम के अगले ...   \n\n                                           WhisperAI  \n0  नामक एक इस्थानीय पेशेवर बास्केटबॉल टीम के अगले...  \n1  नामक एक इस्थानीय पेशेवर बास्केटबॉल टीम के अगले...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OpenHathi</th>\n      <th>WhisperAI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>नामक एक स्थानीय पेशेवर बास्केटबॉल टीम के अगले ...</td>\n      <td>नामक एक इस्थानीय पेशेवर बास्केटबॉल टीम के अगले...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>नामक एक स्थानीय पेशेवर बास्केटबॉल टीम के अगले ...</td>\n      <td>नामक एक इस्थानीय पेशेवर बास्केटबॉल टीम के अगले...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio = whisper.load_audio(\"/kaggle/input/indian-languages-audio-dataset/Indian_Languages_Audio_Dataset/Hindi/10304.mp3\")\noptions = {\"fp16\": False, \"language\": \"hi\", \"task\": \"translate\"}\nresult = model.transcribe(audio, **options)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T12:24:58.569931Z","iopub.execute_input":"2024-03-06T12:24:58.570325Z","iopub.status.idle":"2024-03-06T12:24:59.672311Z","shell.execute_reply.started":"2024-03-06T12:24:58.570284Z","shell.execute_reply":"2024-03-06T12:24:59.671311Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"{'text': ' For the next match of the local basketball team named Hoopers', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 5.0, 'text': ' For the next match of the local basketball team named Hoopers', 'tokens': [50365, 1171, 264, 958, 2995, 295, 264, 2654, 11767, 1469, 4926, 3631, 33338, 50615], 'temperature': 0.0, 'avg_logprob': -0.9067390441894532, 'compression_ratio': 0.9682539682539683, 'no_speech_prob': 0.28305506706237793}], 'language': 'hi'}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom transformers import LlamaTokenizer, LlamaForCausalLM\nimport speech_recognition as sr\nfrom pydub import AudioSegment\n\n# Initialize tokenizer and model\ntokenizer = LlamaTokenizer.from_pretrained('sarvamai/OpenHathi-7B-Hi-v0.1-Base')\nmodel = LlamaForCausalLM.from_pretrained('sarvamai/OpenHathi-7B-Hi-v0.1-Base', torch_dtype=torch.bfloat16)\n\n# Initialize the recognizer\nrecognizer = sr.Recognizer()\n\n# Directory containing audio files\nmp3_directory = \"/kaggle/input/indian-languages-audio-dataset/Indian_Languages_Audio_Dataset/Hindi\"\nwav_file = \"/kaggle/working/audio.wav\"\n\n# List to store transcriptions\ntranscriptions = []\n\n# Loop through each file in the directory\ncount = 0\nfor filename in os.listdir(mp3_directory):\n    if filename.endswith(\".mp3\"):\n        mp3_file = os.path.join(mp3_directory, filename)\n\n        # Convert MP3 to WAV\n        audio = AudioSegment.from_mp3(mp3_file)\n        audio.export(wav_file, format=\"wav\")\n\n        # Open the WAV audio file\n        with sr.AudioFile(wav_file) as source:\n            # Record the audio\n            audio_data = recognizer.record(source)\n\n        # Convert speech to text\n        try:\n            transcript = recognizer.recognize_google(audio_data, language=\"hi-IN\")  \n            transcriptions.append(transcript)\n        except sr.UnknownValueError:\n            print(\"Google Speech Recognition could not understand the audio\")\n            continue\n        except sr.RequestError as e:\n            print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n            continue\n\n        count += 1\n        if count == 100:\n            break\n\n# Create a DataFrame to store the transcriptions\ndf1 = pd.DataFrame({\"Transcription\": transcriptions})\n\n# Save the DataFrame to a CSV file\ndf1.to_csv(\"/kaggle/working/transcriptions.csv\", index=False)\n\nprint(\"Transcriptions saved to transcriptions.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T13:31:54.256480Z","iopub.execute_input":"2024-03-06T13:31:54.257309Z","iopub.status.idle":"2024-03-06T13:36:16.883537Z","shell.execute_reply.started":"2024-03-06T13:31:54.257274Z","shell.execute_reply":"2024-03-06T13:36:16.882381Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e0ed7c92a8946a390297b6871e43abd"}},"metadata":{}},{"name":"stdout","text":"Transcriptions saved to transcriptions.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport whisper\nfrom pydub import AudioSegment\n\n# Load the whisper model\nmodel = whisper.load_model(\"large\")\n\n# Directory containing audio files\nmp3_directory = \"/kaggle/input/indian-languages-audio-dataset/Indian_Languages_Audio_Dataset/Hindi\"\n\n# List to store transcriptions and decoded texts\ntranscriptions = []\ndecoded_texts = []\n\n# Loop through each file in the directory\ncount = 0\nfor filename in os.listdir(mp3_directory):\n    if filename.endswith(\".mp3\"):\n        mp3_file = os.path.join(mp3_directory, filename)\n\n        # Pad or trim audio\n        audio = whisper.load_audio(mp3_file)\n        audio = whisper.pad_or_trim(audio)\n\n        # Make log-Mel spectrogram and move to the same device as the model\n        mel = whisper.log_mel_spectrogram(audio, n_mels=128).to(model.device)\n\n        # Decode the audio\n        options = whisper.DecodingOptions()\n        result1 = whisper.decode(model, mel, options)\n\n        # Store transcription and decoded text\n        transcriptions.append(result1.text)\n        decoded_texts.append(result1.text)\n\n        count += 1\n        if count == 100:\n            break\n\n# Create a DataFrame to store transcriptions and decoded texts\ndf1 = pd.DataFrame({\"Transcriptions\": transcriptions, \"Decoded_Text\": decoded_texts})\n\n# Print the DataFrame\nprint(df1)\n\n# Save the DataFrame to a CSV file\ndf1.to_csv(\"/kaggle/working/transcriptions_and_decoded_texts.csv\", index=False)\n\nprint(\"Transcriptions and decoded texts saved to transcriptions_and_decoded_texts.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T13:49:44.780861Z","iopub.execute_input":"2024-03-06T13:49:44.781763Z","iopub.status.idle":"2024-03-06T13:57:34.780153Z","shell.execute_reply.started":"2024-03-06T13:49:44.781722Z","shell.execute_reply":"2024-03-06T13:57:34.779070Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"                                        Transcription  \\\n0   पर मुझे उसे पुकार कर कुछ पूछने की हिम्मत नहीं ...   \n1   इनकी किमत कितनी है और वे उन्हें कहां से खरीद स...   \n2   अकाउंटेंट के बुनियादी कामों में से एक यह है कि...   \n3                   पूरे कारवार का मालिक होने पर करता   \n4   उतना ही बहतर है। इसलिए, referrals इतने शक्तिशा...   \n..                                                ...   \n95  अपने परिवार के साथ ओ महा गया तो महच 14 साल के ...   \n96           करते हुए वारन ने ओमहा के चार्ल्स हीडर से   \n97  प्रश्नास का संयुक्त राज्य अमेरिका संप्रति वर्क...   \n98  ऐसा सांधार नतीजा सामने आया लेकिन इस तथ्य से कि...   \n99  कि वे शारीरिक शक्ति, विचार या ध्यान के प्रभाव ...   \n\n                                         Decoded_Text  \n0   पर मुझे उसे पुकार कर कुछ पूछने की हिम्मत नहीं ...  \n1   इनकी किमत कितनी है और वे उन्हें कहां से खरीद स...  \n2   अकाउंटेंट के बुनियादी कामों में से एक यह है कि...  \n3                   पूरे कारवार का मालिक होने पर करता  \n4   उतना ही बहतर है। इसलिए, referrals इतने शक्तिशा...  \n..                                                ...  \n95  अपने परिवार के साथ ओ महा गया तो महच 14 साल के ...  \n96           करते हुए वारन ने ओमहा के चार्ल्स हीडर से  \n97  प्रश्नास का संयुक्त राज्य अमेरिका संप्रति वर्क...  \n98  ऐसा सांधार नतीजा सामने आया लेकिन इस तथ्य से कि...  \n99  कि वे शारीरिक शक्ति, विचार या ध्यान के प्रभाव ...  \n\n[100 rows x 2 columns]\nTranscriptions and decoded texts saved to transcriptions_and_decoded_texts.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df1 = pd.DataFrame({\"Open_Hathi\": transcriptions, \"Whisper_AI\": decoded_texts})\ndf1.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:12:35.907416Z","iopub.execute_input":"2024-03-06T14:12:35.908249Z","iopub.status.idle":"2024-03-06T14:12:35.920762Z","shell.execute_reply.started":"2024-03-06T14:12:35.908211Z","shell.execute_reply":"2024-03-06T14:12:35.919520Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                                          Open_Hathi  \\\n0  पर मुझे उसे पुकार कर कुछ पूछने की हिम्मत नहीं ...   \n1  इनकी किमत कितनी है और वे उन्हें कहां से खरीद स...   \n2  अकाउंटेंट के बुनियादी कामों में से एक यह है कि...   \n3                  पूरे कारवार का मालिक होने पर करता   \n4  उतना ही बहतर है। इसलिए, referrals इतने शक्तिशा...   \n\n                                          Whisper_AI  \n0  पर मुझे उसे पुकार कर कुछ पूछने की हिम्मत नहीं ...  \n1  इनकी किमत कितनी है और वे उन्हें कहां से खरीद स...  \n2  अकाउंटेंट के बुनियादी कामों में से एक यह है कि...  \n3                  पूरे कारवार का मालिक होने पर करता  \n4  उतना ही बहतर है। इसलिए, referrals इतने शक्तिशा...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open_Hathi</th>\n      <th>Whisper_AI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>पर मुझे उसे पुकार कर कुछ पूछने की हिम्मत नहीं ...</td>\n      <td>पर मुझे उसे पुकार कर कुछ पूछने की हिम्मत नहीं ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>इनकी किमत कितनी है और वे उन्हें कहां से खरीद स...</td>\n      <td>इनकी किमत कितनी है और वे उन्हें कहां से खरीद स...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>अकाउंटेंट के बुनियादी कामों में से एक यह है कि...</td>\n      <td>अकाउंटेंट के बुनियादी कामों में से एक यह है कि...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>पूरे कारवार का मालिक होने पर करता</td>\n      <td>पूरे कारवार का मालिक होने पर करता</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>उतना ही बहतर है। इसलिए, referrals इतने शक्तिशा...</td>\n      <td>उतना ही बहतर है। इसलिए, referrals इतने शक्तिशा...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install jiwer","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:03:59.243934Z","iopub.execute_input":"2024-03-06T14:03:59.245020Z","iopub.status.idle":"2024-03-06T14:04:14.919304Z","shell.execute_reply.started":"2024-03-06T14:03:59.244981Z","shell.execute_reply":"2024-03-06T14:04:14.917890Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Collecting jiwer\n  Downloading jiwer-3.0.3-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (8.1.7)\nRequirement already satisfied: rapidfuzz<4,>=3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (3.6.1)\nDownloading jiwer-3.0.3-py3-none-any.whl (21 kB)\nInstalling collected packages: jiwer\nSuccessfully installed jiwer-3.0.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport jiwer\n\n# Calculate WER for each column\nwer_open_hathi = jiwer.wer(list(df1['Open_Hathi']), list(df1['Whisper_AI']))\nwer_whisper_ai = jiwer.wer(list(df1['Whisper_AI']), list(df1['Open_Hathi']))  \nprint(f\"WER for Open_Hathi: {wer_open_hathi * 100:.2f} %\")\nprint(f\"WER for Whisper_AI: {wer_whisper_ai * 100:.2f} %\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:14:59.921941Z","iopub.execute_input":"2024-03-06T14:14:59.922627Z","iopub.status.idle":"2024-03-06T14:14:59.938799Z","shell.execute_reply.started":"2024-03-06T14:14:59.922594Z","shell.execute_reply":"2024-03-06T14:14:59.937701Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"WER for Open_Hathi: 0.00 %\nWER for Whisper_AI: 0.00 %\n","output_type":"stream"}]}]}